#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AttentiveFP æ¨¡å‹é¢„æµ‹ç¨‹åº

é¢„æµ‹å‚æ•°åœ¨ç¬¬178è¡Œ
"""

import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler

import torch
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn.models import AttentiveFP

# å¯¼å…¥è®­ç»ƒè„šæœ¬ä¸­çš„å‡½æ•°
from attentivefp_train import æ„å»ºæ•°æ®é›†, æ„å»ºå›¾_from_xyz, ATOMIC_PROPS, é…ä½å…ƒç´ 

class AttentiveFPPredictor:
    def __init__(self, æ¨¡å‹è·¯å¾„, è®­ç»ƒæ•°æ®è·¯å¾„=None, xyzç›®å½•=None, è®¾å¤‡=None):
        """åˆå§‹åŒ–é¢„æµ‹å™¨"""
        if è®¾å¤‡ is None:
            self.è®¾å¤‡ = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.è®¾å¤‡ = è®¾å¤‡
            
        self.æ¨¡å‹è·¯å¾„ = æ¨¡å‹è·¯å¾„
        self.è®­ç»ƒæ•°æ®è·¯å¾„ = è®­ç»ƒæ•°æ®è·¯å¾„
        self.xyzç›®å½• = xyzç›®å½•
        self.æ¨¡å‹ = None
        self.y_scaler = None
        self.å…ƒç´ è¯è¡¨ = None
        
        self.åŠ è½½æ¨¡å‹()
    
    def è·å–æ¨¡å‹å‚æ•°(self):
        """ä½¿ç”¨è®­ç»ƒè„šæœ¬ä¸­çš„ç¡®åˆ‡å‚æ•°"""
        # è¿™äº›å‚æ•°å¿…é¡»ä¸è®­ç»ƒè„šæœ¬å®Œå…¨ä¸€è‡´
        return {
            'in_channels': 15,
            'hidden_channels': 256,
            'edge_dim': 4,
            'num_layers': 4,
            'num_timesteps': 2,
            'dropout': 0.1
        }
    
    def åŠ è½½æ¨¡å‹(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œé…ç½®"""
        if not os.path.exists(self.æ¨¡å‹è·¯å¾„):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.æ¨¡å‹è·¯å¾„}")
        
        print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
        checkpoint = torch.load(self.æ¨¡å‹è·¯å¾„, map_location=self.è®¾å¤‡, weights_only=False)
        
        # è·å–é…ç½®
        state_dict = checkpoint['model_state_dict']
        self.å…ƒç´ è¯è¡¨ = checkpoint.get('element_vocab', [])
        self.y_scaler = checkpoint.get('y_scaler')
        
        æ¨¡å‹å‚æ•° = self.è·å–æ¨¡å‹å‚æ•°()
        
        print(f"ğŸ”§ ä½¿ç”¨è®­ç»ƒå‚æ•°åˆ›å»ºæ¨¡å‹:")
        print(f"   è¾“å…¥ç»´åº¦: {æ¨¡å‹å‚æ•°['in_channels']}")
        print(f"   éšè—å±‚ç»´åº¦: {æ¨¡å‹å‚æ•°['hidden_channels']}")
        print(f"   è¾¹ç‰¹å¾ç»´åº¦: {æ¨¡å‹å‚æ•°['edge_dim']}")
        print(f"   å±‚æ•°: {æ¨¡å‹å‚æ•°['num_layers']}")
        print(f"   æ—¶é—´æ­¥: {æ¨¡å‹å‚æ•°['num_timesteps']}")
        print(f"   Dropout: {æ¨¡å‹å‚æ•°['dropout']}")
        
        # åˆ›å»ºä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´çš„æ¨¡å‹æ¶æ„
        print("ğŸ› ï¸ åˆ›å»ºæ¨¡å‹æ¶æ„...")
        self.æ¨¡å‹ = AttentiveFP(
            in_channels=æ¨¡å‹å‚æ•°['in_channels'],
            hidden_channels=æ¨¡å‹å‚æ•°['hidden_channels'],
            out_channels=1,
            edge_dim=æ¨¡å‹å‚æ•°['edge_dim'],
            num_layers=æ¨¡å‹å‚æ•°['num_layers'],
            num_timesteps=æ¨¡å‹å‚æ•°['num_timesteps'],
            dropout=æ¨¡å‹å‚æ•°['dropout']
        ).to(self.è®¾å¤‡)
        
        # åŠ è½½æƒé‡
        print("ğŸ“¥ åŠ è½½æ¨¡å‹æƒé‡...")
        
        # æ£€æŸ¥æƒé‡é”®åŒ¹é…æƒ…å†µ
        model_keys = set(self.æ¨¡å‹.state_dict().keys())
        state_dict_keys = set(state_dict.keys())
        
        print(f"   æ¨¡å‹å‚æ•°æ•°é‡: {len(model_keys)}")
        print(f"   æ£€æŸ¥ç‚¹å‚æ•°æ•°é‡: {len(state_dict_keys)}")
        
        # æŸ¥æ‰¾ç¼ºå¤±çš„é”®
        missing_in_model = state_dict_keys - model_keys
        missing_in_checkpoint = model_keys - state_dict_keys
        
        if missing_in_model:
            print(f"   âš ï¸ æ£€æŸ¥ç‚¹ä¸­æœ‰ä½†æ¨¡å‹ä¸­ç¼ºå¤±çš„é”®: {missing_in_model}")
        if missing_in_checkpoint:
            print(f"   âš ï¸ æ¨¡å‹ä¸­æœ‰ä½†æ£€æŸ¥ç‚¹ä¸­ç¼ºå¤±çš„é”®: {missing_in_checkpoint}")
        
        # å°è¯•åŠ è½½æƒé‡
        try:
            self.æ¨¡å‹.load_state_dict(state_dict, strict=False)
            print("   âœ… æƒé‡åŠ è½½æˆåŠŸ (strict=False)")
        except Exception as e:
            print(f"   âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
            raise
        
        self.æ¨¡å‹.eval()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    def æ„å»ºé¢„æµ‹å›¾(self, xyzæ–‡ä»¶è·¯å¾„):
        """ä¸ºé¢„æµ‹æ„å»ºå›¾æ•°æ®"""
        if not self.å…ƒç´ è¯è¡¨:
            raise ValueError("å…ƒç´ è¯è¡¨æœªåˆå§‹åŒ–")
        
        g = æ„å»ºå›¾_from_xyz(xyzæ–‡ä»¶è·¯å¾„, self.å…ƒç´ è¯è¡¨)
        
        data = Data(
            x=g["x"],
            edge_index=g["edge_index"],
            edge_attr=g["edge_attr"],
            y=torch.tensor([0.0])  # å ä½ç¬¦
        )
        data.batch = torch.zeros(len(g["x"]), dtype=torch.long)
        
        return data, g
    
    def é¢„æµ‹å•ä¸ªç»“æ„(self, xyzæ–‡ä»¶è·¯å¾„):
        """é¢„æµ‹å•ä¸ªXYZç»“æ„çš„æ€§è´¨"""
        try:
            if not os.path.exists(xyzæ–‡ä»¶è·¯å¾„):
                raise FileNotFoundError(f"XYZæ–‡ä»¶ä¸å­˜åœ¨: {xyzæ–‡ä»¶è·¯å¾„}")
            
            data, g = self.æ„å»ºé¢„æµ‹å›¾(xyzæ–‡ä»¶è·¯å¾„)
            
            # é¢„æµ‹
            with torch.no_grad():
                data = data.to(self.è®¾å¤‡)
                out = self.æ¨¡å‹(data.x, data.edge_index, data.edge_attr, data.batch)
                
                # å¤„ç†è¾“å‡º
                if out.dim() > 1:
                    out = out.view(-1)
                
                prediction = out.cpu().numpy()[0]
                
                # åæ ‡å‡†åŒ–
                if self.y_scaler is not None:
                    prediction = self.y_scaler.inverse_transform([[prediction]])[0, 0]
            
            return {
                'æ–‡ä»¶': os.path.basename(xyzæ–‡ä»¶è·¯å¾„),
                'é¢„æµ‹å¸é™„èƒ½(eV)': float(prediction),
                'åŸå­æ•°': len(g["å…ƒç´ åˆ—è¡¨"]),
                'è¾¹æ•°é‡': g["edge_index"].shape[1] // 2,
                'ä¸­å¿ƒé‡‘å±': g["å…ƒç´ åˆ—è¡¨"][g["metal_index"]],
                'æ€»åŸå­': g["å…ƒç´ åˆ—è¡¨"]
            }
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥ {xyzæ–‡ä»¶è·¯å¾„}: {e}")
            return None
    
    def é¢„æµ‹æ•°æ®é›†(self, csvæ–‡ä»¶è·¯å¾„, xyzç›®å½•):
        """é¢„æµ‹æ•´ä¸ªæ•°æ®é›†çš„æ€§èƒ½"""
        print(f"ğŸ“ˆ å¼€å§‹é¢„æµ‹æ•°æ®é›†...")
        print(f"   CSVæ–‡ä»¶: {csvæ–‡ä»¶è·¯å¾„}")
        print(f"   XYZç›®å½•: {xyzç›®å½•}")
        
        # æ„å»ºæ•°æ®é›†
        pyg_list, _, _, _ = æ„å»ºæ•°æ®é›†(csvæ–‡ä»¶è·¯å¾„, xyzç›®å½•, "d_band_center", r_max=5.0)
        
        if len(pyg_list) == 0:
            raise ValueError("æ²¡æœ‰æ„å»ºåˆ°æœ‰æ•ˆçš„å›¾æ•°æ®")
        
        print(f"   æ ·æœ¬æ•°é‡: {len(pyg_list)}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        test_loader = DataLoader(pyg_list, batch_size=16, shuffle=False)
        
        # æ‰¹é‡é¢„æµ‹
        all_true = []
        all_pred = []
        all_names = []
        
        self.æ¨¡å‹.eval()
        with torch.no_grad():
            for batch in test_loader:
                batch = batch.to(self.è®¾å¤‡)
                out = self.æ¨¡å‹(batch.x, batch.edge_index, batch.edge_attr, batch.batch)
                
                if out.dim() > 1:
                    out = out.view(-1)
                
                # åæ ‡å‡†åŒ–é¢„æµ‹å€¼
                if self.y_scaler is not None:
                    out_denorm = self.y_scaler.inverse_transform(out.cpu().numpy().reshape(-1, 1)).flatten()
                    all_pred.extend(out_denorm.tolist())
                else:
                    all_pred.extend(out.cpu().numpy().tolist())
                
                # æ”¶é›†çœŸå®å€¼
                if hasattr(batch, 'original_y'):
                    all_true.extend(batch.original_y.cpu().numpy().tolist())
                else:
                    all_true.extend(batch.y.view(-1).cpu().numpy().tolist())
                
                # æ”¶é›†åç§°
                if hasattr(batch, 'name'):
                    all_names.extend(batch.name)
                else:
                    all_names.extend([f"sample_{i}" for i in range(len(batch.y))])
        
        return np.array(all_true), np.array(all_pred), all_names
    
    def ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š(self, y_true, y_pred, è¾“å‡ºç›®å½•):
        """ç”Ÿæˆé¢„æµ‹è¯„ä¼°æŠ¥å‘Šå’Œå›¾è¡¨"""
        os.makedirs(è¾“å‡ºç›®å½•, exist_ok=True)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        mse = mean_squared_error(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)
        rmse = np.sqrt(mse)
        
        print(f"\nğŸ“Š é¢„æµ‹æ€§èƒ½è¯„ä¼°:")
        print(f"   æ ·æœ¬æ•°é‡: {len(y_true)}")
        print(f"   MSE:  {mse:.6f}")
        print(f"   RMSE: {rmse:.6f} eV")
        print(f"   MAE:  {mae:.6f} eV")
        print(f"   RÂ²:   {r2:.4f}")
        
        # ç”ŸæˆParity Plot
        self.ç»˜åˆ¶_parity_plot(y_true, y_pred, è¾“å‡ºç›®å½•, mse, mae, r2, rmse)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        self.ä¿å­˜é¢„æµ‹ç»“æœ(y_true, y_pred, è¾“å‡ºç›®å½•, mse, mae, r2, rmse)
        
        return mse, mae, r2, rmse
    
    def ç»˜åˆ¶_parity_plot(self, y_true, y_pred, è¾“å‡ºç›®å½•, mse, mae, r2, rmse):
        """ç»˜åˆ¶Parity Plot"""
        plt.figure(figsize=(6.5, 6))
        
        # ç»˜åˆ¶æ•£ç‚¹å›¾
        plt.scatter(y_true, y_pred, alpha=0.7, s=50, edgecolors='w', linewidth=0.5)
        
        # ç»˜åˆ¶å¯¹è§’çº¿
        min_val = min(y_true.min(), y_pred.min())
        max_val = max(y_true.max(), y_pred.max())
        margin = (max_val - min_val) * 0.05
        
        plt.plot([min_val - margin, max_val + margin], 
                 [min_val - margin, max_val + margin], 
                 'r--', alpha=0.8, linewidth=2, label='Prefect prediction')
        
        plt.xlabel('True attached_energy_ev (eV)', fontsize=12)
        plt.ylabel('Predicted attached_energy_ev (eV)', fontsize=12)
        plt.title(f'AttentiveFP Prediction Result\nRÂ² = {r2:.4f}, RMSE = {rmse:.4f} eV', fontsize=14)
        plt.grid(True, alpha=0.3)
        plt.legend()
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬æ¡†
        textstr = f'N = {len(y_true)}\nRÂ² = {r2:.4f}\nRMSE = {rmse:.4f} eV\nMAE = {mae:.4f} eV'
        props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
        plt.text(0.05, 0.95, textstr, transform=plt.gca().transAxes, fontsize=10,
                 verticalalignment='top', bbox=props)
        
        plt.tight_layout()
        plt.savefig(os.path.join(è¾“å‡ºç›®å½•, "prediction_parity_plot.png"), 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… Parity plot å·²ä¿å­˜: {è¾“å‡ºç›®å½•}/prediction_parity_plot.png")
    
    def ä¿å­˜é¢„æµ‹ç»“æœ(self, y_true, y_pred, è¾“å‡ºç›®å½•, mse, mae, r2, rmse):
        """ä¿å­˜è¯¦ç»†çš„é¢„æµ‹ç»“æœ"""
        results_df = pd.DataFrame({
            'true_value': y_true,
            'pred_value': y_pred,
            'absolute_error': np.abs(y_true - y_pred),
            'relative_error_percent': np.abs((y_true - y_pred) / (np.abs(y_true) + 1e-8)) * 100
        })
        
        # ä¿å­˜åˆ°CSVæ–‡ä»¶
        results_df.to_csv(os.path.join(è¾“å‡ºç›®å½•, "prediction_results.csv"), index=False)
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        ç»Ÿè®¡ä¿¡æ¯ = {
            'MSE': float(mse),
            'RMSE': float(rmse),
            'MAE': float(mae),
            'R2': float(r2),
            'æ ·æœ¬æ•°é‡': len(y_true)
        }
        
        with open(os.path.join(è¾“å‡ºç›®å½•, "prediction_stats.json"), 'w') as f:
            json.dump(ç»Ÿè®¡ä¿¡æ¯, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜")
        print(f"   å¹³å‡ç»å¯¹è¯¯å·®: {results_df['absolute_error'].mean():.4f} eV")
        print(f"   æœ€å¤§ç»å¯¹è¯¯å·®: {results_df['absolute_error'].max():.4f} eV")

def main():
    """ä¸»å‡½æ•° - ä½¿ç”¨ç¤ºä¾‹"""
    # é…ç½®å‚æ•°
    æ¨¡å‹è·¯å¾„ = "output/best_attentivefp.pt"
    è®­ç»ƒæ•°æ®è·¯å¾„ = "data.csv"
    xyzç›®å½• = "xyzs"
    è¾“å‡ºç›®å½• = "prediction_results"
    
    try:
        # åˆ›å»ºé¢„æµ‹å™¨
        print("ğŸš€ åˆå§‹åŒ– AttentiveFP é¢„æµ‹å™¨...")
        predictor = AttentiveFPPredictor(æ¨¡å‹è·¯å¾„, è®­ç»ƒæ•°æ®è·¯å¾„, xyzç›®å½•)
        
        # é¢„æµ‹æ•´ä¸ªæ•°æ®é›†
        print("\nğŸ“ˆ å¼€å§‹æ‰¹é‡é¢„æµ‹æ•°æ®é›†...")
        y_true, y_pred, names = predictor.é¢„æµ‹æ•°æ®é›†(è®­ç»ƒæ•°æ®è·¯å¾„, xyzç›®å½•)
        
        # ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
        predictor.ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š(y_true, y_pred, è¾“å‡ºç›®å½•)
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()